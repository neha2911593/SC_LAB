#Perceptron Delta Rule
import numpy as np

# Inputs (4 samples, 2 features)
X = np.array([[0,0], [0,1], [1,0], [1,1]])
# Targets (AND logic)
y = np.array([0, 0, 0, 1])

# Initialize weights and bias
w = np.zeros(2)
b = 0
lr = 0.1  # learning rate

def activation(x):
    # Linear output (no threshold, as delta rule works with continuous values)
    return x

epochs = 10

for epoch in range(epochs):
    for xi, target in zip(X, y):
        output = activation(np.dot(w, xi) + b)
        error = target - output
        w += lr * error * xi
        b += lr * error
    print(f"Epoch {epoch+1}: Weights = {w}, Bias = {b}")

print("\nFinal Weights:", w)
print("Final Bias:", b)
